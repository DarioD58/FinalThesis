{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZavRad.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFfCmkowEZYA"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from PIL import Image\n",
        "from torchvision.datasets import CIFAR100\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torchsummary import summary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMsvxwwaFFyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154af7b1-bc43-44fb-d760-e9d15d3f174a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIRPRN3Av8rz"
      },
      "source": [
        "#All the parameters\n",
        "epoch = 50\n",
        "lr = 0.1\n",
        "weight_decay = 0.0001\n",
        "momentum = 0.9\n",
        "gamma = 0.99\n",
        "resnet_type = 5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjViR5N-lGpA"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channel_num, stride, downsample_layer = None):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.downsample = downsample_layer\n",
        "    \n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(int(channel_num/stride), channel_num, 3, stride, padding=1),\n",
        "        nn.BatchNorm2d(channel_num),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(channel_num, channel_num, 3, int(stride/stride), padding=1),\n",
        "        nn.BatchNorm2d(channel_num),\n",
        "    )\n",
        "    self.relu = nn.ReLU() #Definiramo izvan bloka zbog skip connectiona\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip_connection = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    if(skip_connection.shape != x.shape):\n",
        "      skip_connection = self.downsample(skip_connection)\n",
        "    x = skip_connection + x\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5aJqTgJsFI_"
      },
      "source": [
        "class ResidualNetwork(nn.Module):\n",
        "  def __init__(self, channel_num=16):\n",
        "    super(ResidualNetwork, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3, channel_num, 3, padding=1),\n",
        "      nn.BatchNorm2d(channel_num),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    res_blocks = []\n",
        "\n",
        "    for i in range(3 * resnet_type):\n",
        "      if(i != 0 and i % resnet_type == 0):\n",
        "        channel_num = channel_num*2\n",
        "        res_blocks.append(ResidualBlock(channel_num, 2, nn.Sequential(\n",
        "            nn.Conv2d(int(channel_num/2), channel_num, 1, 2),\n",
        "            nn.BatchNorm2d(channel_num),\n",
        "        )))\n",
        "      else:\n",
        "        res_blocks.append(ResidualBlock(channel_num, 1))\n",
        "\n",
        "    self.residualblocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "    self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(64, 100, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.residualblocks(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    out = self.fc(x)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTwwE290NRH8"
      },
      "source": [
        "trainTransform = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "testTransform = transforms.Compose([    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "\n",
        "trainSet = torchvision.datasets.CIFAR100(root='./drive/MyDrive/Zavrsni/data', train=True,\n",
        "                    download=False, transform=trainTransform)\n",
        "testSet = torchvision.datasets.CIFAR100(root='./drive/MyDrive/Zavrsni/data', train=False,\n",
        "                    download=False, transform=testTransform)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=128,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=128,\n",
        "                                         shuffle=True, num_workers=0)\n",
        "\n",
        "classes=pickle.load(open('./drive/MyDrive/Zavrsni/data/cifar-100-python/meta', 'rb'))\n",
        "classes=classes['fine_label_names']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lGbeSSvMY0h"
      },
      "source": [
        "def evaluate(net, type, save_path):\n",
        "    \"\"\"\n",
        "    Performs the evaluation of the current performance of a\n",
        "    given convolutional network. It can perform the evaluation on \n",
        "    both training and testing sets. Standard evaluation metrics are\n",
        "    calcualted such as, accuracy and confusion matrix.\n",
        "    Parameters\n",
        "    ----------\n",
        "    net: ConvolutionalModel\n",
        "        ConvNet whose performance needs to be evaluated.\n",
        "    type: bool\n",
        "        True if eval is made on testing set, false otherwise\n",
        "    Return\n",
        "    ------\n",
        "    loss\n",
        "        Current loss on the chosen set\n",
        "    accuracy\n",
        "        Current acc on the chosen set\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda')\n",
        "    f = open(save_path, \"a+\")\n",
        "    net.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    confMatrix = np.zeros((100, 100), int)\n",
        "    lossFunc = nn.CrossEntropyLoss()\n",
        "    accLoss = 0\n",
        "    if type:\n",
        "        with torch.no_grad():\n",
        "            for data in testLoader:\n",
        "                images, labels = data\n",
        "                images = images.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "\n",
        "                output = net.forward(images)\n",
        "                loss = lossFunc(output, labels)\n",
        "                _, predictions = torch.max(output.data, 1)\n",
        "                total += labels.size(0)\n",
        "                accLoss += loss.item()\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                for j in range(labels.size(0)):\n",
        "                    confMatrix[predictions[j], labels[j]] += 1\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            for data in trainLoader:\n",
        "                images, labels = data\n",
        "                images = images.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "\n",
        "                output = net.forward(images)\n",
        "                loss = lossFunc(output, labels)\n",
        "                _, predictions = torch.max(output.data, 1)\n",
        "                total += labels.size(0)\n",
        "                accLoss += loss.item()\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                for j in range(labels.size(0)):\n",
        "                    confMatrix[predictions[j], labels[j]] += 1\n",
        "\n",
        "    print(\"Accuracy of the neural network on CIFAR_100 is: %.2f %%\" %((correct/total)*100))\n",
        "    f.write(\"Accuracy: \" + str(((correct/total)*100)) + '\\n')\n",
        "    f.write(str(classes) + '\\n')\n",
        "    f.write(str(confMatrix) + '\\n')\n",
        "    prec, recall = specificMetrics(confMatrix)\n",
        "    f.write(str(prec) + '\\n')\n",
        "    f.write(str(recall) + '\\n')\n",
        "    f.close()\n",
        "    return (accLoss/(total/trainLoader.batch_size)), (correct/total)\n",
        "\n",
        "def specificMetrics(confMatrix):\n",
        "    \"\"\"\n",
        "    Calculates precision and recall from a given confusion\n",
        "    matrix and returns calculated metrics.\n",
        "    Parameters\n",
        "    ----------\n",
        "    confMatrix: n x n numpy array\n",
        "        Made from the predictions and true labels of a\n",
        "        given set of data\n",
        "    Return\n",
        "    ------\n",
        "    precc\n",
        "        Precision on all classes\n",
        "    recal \n",
        "        Recall on all classes\n",
        "    \"\"\"\n",
        "    precc = np.zeros(np.size(confMatrix, 0))\n",
        "    recal = np.zeros(np.size(confMatrix, 0))\n",
        "    for i in range(np.size(confMatrix, 0)):\n",
        "        tp = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        for j in range(np.size(confMatrix, 0)):\n",
        "            if i == j:\n",
        "                tp += confMatrix[i, j]\n",
        "            else:\n",
        "                fn += confMatrix[j, i]\n",
        "                fp += confMatrix[i, j]\n",
        "            \n",
        "        precc[i] += tp/(tp + fp)\n",
        "        recal[i] += tp/(tp + fn)\n",
        "\n",
        "    return precc, recal"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6bBowvdNDrC"
      },
      "source": [
        "def plot_training_progress(save_dir, data):\n",
        "  fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16,8))\n",
        "\n",
        "  linewidth = 2\n",
        "  legend_size = 10\n",
        "  train_color = 'm'\n",
        "  val_color = 'c'\n",
        "\n",
        "  num_points = len(data['train_loss'])\n",
        "  x_data = np.linspace(1, num_points, num_points)\n",
        "  ax1.set_title('Cross-entropy loss')\n",
        "  ax1.plot(x_data, data['train_loss'], marker='o', color=train_color,\n",
        "           linewidth=linewidth, linestyle='-', label='train')\n",
        "  ax1.plot(x_data, data['valid_loss'], marker='o', color=val_color,\n",
        "           linewidth=linewidth, linestyle='-', label='validation')\n",
        "  ax1.legend(loc='upper right', fontsize=legend_size)\n",
        "  ax2.set_title('Average class accuracy')\n",
        "  ax2.plot(x_data, data['train_acc'], marker='o', color=train_color,\n",
        "           linewidth=linewidth, linestyle='-', label='train')\n",
        "  ax2.plot(x_data, data['valid_acc'], marker='o', color=val_color,\n",
        "           linewidth=linewidth, linestyle='-', label='validation')\n",
        "  ax2.legend(loc='upper left', fontsize=legend_size)\n",
        "  ax3.set_title('Learning rate')\n",
        "  ax3.plot(x_data, data['lr'], marker='o', color=train_color,\n",
        "           linewidth=linewidth, linestyle='-', label='learning_rate')\n",
        "  ax3.legend(loc='upper left', fontsize=legend_size)\n",
        "\n",
        "  save_path = os.path.join(save_dir, 'plots/training_plot4.png')\n",
        "  print('Plotting in: ', save_path)\n",
        "  plt.savefig(save_path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXWetGDoMHLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6fcc39-0857-469b-aa45-cb6aa9d07e58"
      },
      "source": [
        "def trainNetwork():\n",
        "    \"\"\"Performs a standard procedure for training a neural network.\n",
        "    Training progress after each learning epoch is evaluated in order to\n",
        "    gain insigth into ConvNets continuous performance.\n",
        "    Important notes\n",
        "    ---------------\n",
        "    Loss function: Cross entropy loss\n",
        "\n",
        "    Optimizer: Adam\n",
        "    \n",
        "    Scheduler: ExponentialLR\n",
        "    \"\"\"\n",
        "    plot_data = {}\n",
        "    plot_data['train_loss'] = []\n",
        "    plot_data['valid_loss'] = []\n",
        "    plot_data['train_acc'] = []\n",
        "    plot_data['valid_acc'] = []\n",
        "    plot_data['lr'] = []\n",
        "    SAVE_DIR = '/content/drive/MyDrive/Zavrsni'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    net = ResidualNetwork().to(device=device)\n",
        "    summary(net, (3, 32, 32))\n",
        "\n",
        "    lossFunc = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
        "    \n",
        "    for e in range(epoch):\n",
        "    \n",
        "        accLoss = 0.0\n",
        "\n",
        "        for i, data in enumerate(trainLoader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net.forward(inputs)\n",
        "            loss = lossFunc(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            accLoss += loss.item()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(\"Epoch: %d, Iteration: %5d, Loss: %.3f\" % ((e + 1), (i), (accLoss / (i + 1))))\n",
        "                \n",
        "        train_loss, train_acc = evaluate(net, False, os.path.join(SAVE_DIR, \"eval/train_eval4\"))\n",
        "        val_loss, val_acc = evaluate(net, True, os.path.join(SAVE_DIR, \"eval/test_eval4\"))\n",
        "\n",
        "        plot_data['train_loss'] += [train_loss]\n",
        "        plot_data['valid_loss'] += [val_loss]\n",
        "        plot_data['train_acc'] += [train_acc]\n",
        "        plot_data['valid_acc'] += [val_acc]\n",
        "        plot_data['lr'] += [scheduler.get_last_lr()]\n",
        "\n",
        "        scheduler.step()\n",
        "    \n",
        "    val_loss, val_acc = evaluate(net, True, os.path.join(SAVE_DIR, \"eval/final_eval4\"))\n",
        "    plot_training_progress(SAVE_DIR, plot_data)\n",
        "    PATH = os.path.join(SAVE_DIR, \"CIFAR_100/cifar_net3.pth\")\n",
        "    torch.save(net.state_dict(), PATH)\n",
        "\n",
        "#trainNetwork()\n",
        "device = torch.device('cuda')\n",
        "net = ResidualNetwork().to(device=device)\n",
        "summary(net, (3, 32, 32))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "              ReLU-6           [-1, 16, 32, 32]               0\n",
            "            Conv2d-7           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "              ReLU-9           [-1, 16, 32, 32]               0\n",
            "    ResidualBlock-10           [-1, 16, 32, 32]               0\n",
            "           Conv2d-11           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
            "             ReLU-13           [-1, 16, 32, 32]               0\n",
            "           Conv2d-14           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
            "             ReLU-16           [-1, 16, 32, 32]               0\n",
            "    ResidualBlock-17           [-1, 16, 32, 32]               0\n",
            "           Conv2d-18           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
            "             ReLU-20           [-1, 16, 32, 32]               0\n",
            "           Conv2d-21           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
            "             ReLU-23           [-1, 16, 32, 32]               0\n",
            "    ResidualBlock-24           [-1, 16, 32, 32]               0\n",
            "           Conv2d-25           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
            "             ReLU-27           [-1, 16, 32, 32]               0\n",
            "           Conv2d-28           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
            "             ReLU-30           [-1, 16, 32, 32]               0\n",
            "    ResidualBlock-31           [-1, 16, 32, 32]               0\n",
            "           Conv2d-32           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-33           [-1, 16, 32, 32]              32\n",
            "             ReLU-34           [-1, 16, 32, 32]               0\n",
            "           Conv2d-35           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
            "             ReLU-37           [-1, 16, 32, 32]               0\n",
            "    ResidualBlock-38           [-1, 16, 32, 32]               0\n",
            "           Conv2d-39           [-1, 32, 16, 16]           4,640\n",
            "      BatchNorm2d-40           [-1, 32, 16, 16]              64\n",
            "             ReLU-41           [-1, 32, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           Conv2d-44           [-1, 32, 16, 16]             544\n",
            "      BatchNorm2d-45           [-1, 32, 16, 16]              64\n",
            "             ReLU-46           [-1, 32, 16, 16]               0\n",
            "    ResidualBlock-47           [-1, 32, 16, 16]               0\n",
            "           Conv2d-48           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-49           [-1, 32, 16, 16]              64\n",
            "             ReLU-50           [-1, 32, 16, 16]               0\n",
            "           Conv2d-51           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-52           [-1, 32, 16, 16]              64\n",
            "             ReLU-53           [-1, 32, 16, 16]               0\n",
            "    ResidualBlock-54           [-1, 32, 16, 16]               0\n",
            "           Conv2d-55           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-56           [-1, 32, 16, 16]              64\n",
            "             ReLU-57           [-1, 32, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "             ReLU-60           [-1, 32, 16, 16]               0\n",
            "    ResidualBlock-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-63           [-1, 32, 16, 16]              64\n",
            "             ReLU-64           [-1, 32, 16, 16]               0\n",
            "           Conv2d-65           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
            "             ReLU-67           [-1, 32, 16, 16]               0\n",
            "    ResidualBlock-68           [-1, 32, 16, 16]               0\n",
            "           Conv2d-69           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-70           [-1, 32, 16, 16]              64\n",
            "             ReLU-71           [-1, 32, 16, 16]               0\n",
            "           Conv2d-72           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
            "             ReLU-74           [-1, 32, 16, 16]               0\n",
            "    ResidualBlock-75           [-1, 32, 16, 16]               0\n",
            "           Conv2d-76             [-1, 64, 8, 8]          18,496\n",
            "      BatchNorm2d-77             [-1, 64, 8, 8]             128\n",
            "             ReLU-78             [-1, 64, 8, 8]               0\n",
            "           Conv2d-79             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
            "           Conv2d-81             [-1, 64, 8, 8]           2,112\n",
            "      BatchNorm2d-82             [-1, 64, 8, 8]             128\n",
            "             ReLU-83             [-1, 64, 8, 8]               0\n",
            "    ResidualBlock-84             [-1, 64, 8, 8]               0\n",
            "           Conv2d-85             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-86             [-1, 64, 8, 8]             128\n",
            "             ReLU-87             [-1, 64, 8, 8]               0\n",
            "           Conv2d-88             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
            "             ReLU-90             [-1, 64, 8, 8]               0\n",
            "    ResidualBlock-91             [-1, 64, 8, 8]               0\n",
            "           Conv2d-92             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-93             [-1, 64, 8, 8]             128\n",
            "             ReLU-94             [-1, 64, 8, 8]               0\n",
            "           Conv2d-95             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
            "             ReLU-97             [-1, 64, 8, 8]               0\n",
            "    ResidualBlock-98             [-1, 64, 8, 8]               0\n",
            "           Conv2d-99             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-100             [-1, 64, 8, 8]             128\n",
            "            ReLU-101             [-1, 64, 8, 8]               0\n",
            "          Conv2d-102             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
            "            ReLU-104             [-1, 64, 8, 8]               0\n",
            "   ResidualBlock-105             [-1, 64, 8, 8]               0\n",
            "          Conv2d-106             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-107             [-1, 64, 8, 8]             128\n",
            "            ReLU-108             [-1, 64, 8, 8]               0\n",
            "          Conv2d-109             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-110             [-1, 64, 8, 8]             128\n",
            "            ReLU-111             [-1, 64, 8, 8]               0\n",
            "   ResidualBlock-112             [-1, 64, 8, 8]               0\n",
            "AdaptiveAvgPool2d-113             [-1, 64, 1, 1]               0\n",
            "          Linear-114                  [-1, 100]           6,500\n",
            "================================================================\n",
            "Total params: 473,988\n",
            "Trainable params: 473,988\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 8.22\n",
            "Params size (MB): 1.81\n",
            "Estimated Total Size (MB): 10.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}